# streamlit_station_app.py
# Streamlit app for exploring Seoul subway station locations
# Save this file and run with: streamlit run streamlit_station_app.py
# Place station.csv in the same directory as this script.

import streamlit as st
import pandas as pd
import numpy as np
from math import radians, cos, sin, asin, sqrt

# Visualization
import plotly.express as px

# Try to import folium and streamlit_folium if available; fall back to st.map
try:
    import folium
    from streamlit_folium import st_folium
    FOLIUM_AVAILABLE = True
except Exception:
    FOLIUM_AVAILABLE = False

st.set_page_config(page_title="Seoul Station Explorer", layout="wide")

# ---------------------- Helper functions ----------------------
@st.cache_data
def load_data(path: str = "station.csv") -> pd.DataFrame:
    """Load station CSV with common Korean encodings fallback."""
    encodings = ["cp949", "euc-kr", "utf-8-sig", "utf-8"]
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            df.columns = df.columns.str.strip()
            return df
        except Exception:
            continue
    raise UnicodeDecodeError("Unable to read CSV with tried encodings.")


def haversine(lon1, lat1, lon2, lat2):
    # haversine distance in kilometers
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
    c = 2 * asin(sqrt(a))
    km = 6371 * c
    return km

# ---------------------- App layout ----------------------
st.title("ğŸš‰ Seoul Subway Station Explorer")
st.markdown(
    "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ë…¸ì„ ë³„ ë¶„í¬, ì§€ë„ ì‹œê°í™”, ê²€ìƒ‰(ìœ„ë„/ê²½ë„ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì—­ ì°¾ê¸°), íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# Load data
with st.spinner("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
    try:
        df = load_data("station.csv")
    except Exception as e:
        st.error(f"station.csv íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

# Basic column standardization
expected_cols = {"ì—­ID": None, "ì—­ëª…": None, "ë…¸ì„ ëª…": None, "ìœ„ë„": None, "ê²½ë„": None}
cols_lower = {c.lower(): c for c in df.columns}
# Try to map typical Korean/English variations
col_map = {}
for exp in expected_cols.keys():
    lower = exp.lower()
    if lower in cols_lower:
        col_map[cols_lower[lower]] = exp
# If direct mapping not found, try fuzzy alternatives
candidates = {
    "id": ["id", "ì—­id", "station_id"],
    "name": ["name", "ì—­ëª…", "station_name", "ì—­"],
    "line": ["ë…¸ì„ ëª…", "line", "line_name", "ë…¸ì„ "],
    "lat": ["ìœ„ë„", "latitude", "lat"],
    "lon": ["ê²½ë„", "longitude", "lon", "lng"]
}
for std, opts in candidates.items():
    for o in opts:
        for c in df.columns:
            if c.lower() == o:
                if std == 'id':
                    df = df.rename(columns={c: 'ì—­ID'})
                elif std == 'name':
                    df = df.rename(columns={c: 'ì—­ëª…'})
                elif std == 'line':
                    df = df.rename(columns={c: 'ë…¸ì„ ëª…'})
                elif std == 'lat':
                    df = df.rename(columns={c: 'ìœ„ë„'})
                elif std == 'lon':
                    df = df.rename(columns={c: 'ê²½ë„'})

# Ensure required columns exist
required = ["ì—­ID", "ì—­ëª…", "ë…¸ì„ ëª…", "ìœ„ë„", "ê²½ë„"]
if not all(c in df.columns for c in required):
    st.error("CSVì— í•„ìš”í•œ ì—´(ì—­ID, ì—­ëª…, ë…¸ì„ ëª…, ìœ„ë„, ê²½ë„)ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.write("í˜„ì¬ ì—´:", df.columns.tolist())
    st.stop()

# Convert coords to numeric
for c in ["ìœ„ë„", "ê²½ë„"]:
    df[c] = pd.to_numeric(df[c], errors="coerce")

# Sidebar controls
st.sidebar.header("í•„í„° & ê²€ìƒ‰")
lines = ["ì „ì²´"] + sorted(df["ë…¸ì„ ëª…"].astype(str).unique().tolist())
selected_line = st.sidebar.selectbox("ë…¸ì„  ì„ íƒ", lines)
search_name = st.sidebar.text_input("ì—­ëª…ìœ¼ë¡œ ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜ ê°€ëŠ¥)")

st.sidebar.markdown("---")
st.sidebar.subheader("ê°€ì¥ ê°€ê¹Œìš´ ì—­ ì°¾ê¸°")
input_lat = st.sidebar.number_input("ìœ„ë„ (ì˜ˆ: 37.55)", value=37.55, format="%.6f")
input_lon = st.sidebar.number_input("ê²½ë„ (ì˜ˆ: 126.97)", value=126.97, format="%.6f")
if st.sidebar.button("ê°€ê¹Œìš´ ì—­ ì°¾ê¸°"):
    df['distance_km'] = df.apply(lambda r: haversine(input_lon, input_lat, r['ê²½ë„'], r['ìœ„ë„']), axis=1)
    nearest = df.sort_values('distance_km').iloc[0]
    st.sidebar.success(f"ê°€ì¥ ê°€ê¹Œìš´ ì—­: {nearest['ì—­ëª…']} ({nearest['ë…¸ì„ ëª…']}) â€” {nearest['distance_km']:.3f} km")

st.sidebar.markdown("---")
st.sidebar.markdown("ì•± ì„¤ì •")
if FOLIUM_AVAILABLE:
    st.sidebar.caption("ì§€ë„: folium + streamlit_folium ì‚¬ìš©")
else:
    st.sidebar.caption("ì§€ë„: ê¸°ë³¸ st.map ì‚¬ìš© (folium ë˜ëŠ” streamlit_folium ì„¤ì¹˜ ê¶Œì¥)")

# Apply filters
filtered = df.copy()
if selected_line != "ì „ì²´":
    filtered = filtered[filtered['ë…¸ì„ ëª…'] == selected_line]
if search_name:
    filtered = filtered[filtered['ì—­ëª…'].astype(str).str.contains(search_name, na=False)]

col1, col2 = st.columns([2, 1])
with col1:
    st.subheader("ì§€ë„")
    if filtered.empty:
        st.info("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if FOLIUM_AVAILABLE:
            # Center map on mean coordinates
            mean_lat = filtered['ìœ„ë„'].mean()
            mean_lon = filtered['ê²½ë„'].mean()
            m = folium.Map(location=[mean_lat, mean_lon], zoom_start=12)
            for _, r in filtered.iterrows():
                popup = f"<b>{r['ì—­ëª…']}</b><br/>{r['ë…¸ì„ ëª…']}"
                folium.CircleMarker([r['ìœ„ë„'], r['ê²½ë„']], radius=5, popup=popup).add_to(m)
            st_folium(m, width="100%", height=600)
        else:
            # Use st.map as a fallback
            st.map(filtered.rename(columns={'ìœ„ë„':'lat','ê²½ë„':'lon'})[['lat','lon']])

with col2:
    st.subheader("ìš”ì•½ í†µê³„")
    st.metric("í•„í„°ëœ ì—­ ìˆ˜", len(filtered))
    st.write("ë…¸ì„  ìˆ˜:", filtered['ë…¸ì„ ëª…'].nunique())
    st.write("ìœ„ë„ í‰ê·  / ê²½ë„ í‰ê· :")
    st.write(filtered[['ìœ„ë„','ê²½ë„']].mean().round(6))

    st.markdown("### ë…¸ì„ ë³„ ì—­ ê°œìˆ˜")
    counts = filtered['ë…¸ì„ ëª…'].value_counts().reset_index()
    counts.columns = ['ë…¸ì„ ëª…','ì—­ê°œìˆ˜']
    st.dataframe(counts)

    # Download
    csv = filtered.to_csv(index=False).encode('utf-8-sig')
    st.download_button("í•„í„°ëœ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="stations_filtered.csv", mime='text/csv')

st.markdown("---")

# Plot: ë…¸ì„ ë³„ ì—­ ê°œìˆ˜ (ì „ì²´ ë°ì´í„° ê¸°ì¤€)
st.subheader("ë…¸ì„ ë³„ ì—­ ê°œìˆ˜ (ì „ì²´ ë°ì´í„° ê¸°ì¤€)")
counts_all = df['ë…¸ì„ ëª…'].value_counts().reset_index()
counts_all.columns = ['ë…¸ì„ ëª…','ì—­ê°œìˆ˜']
fig = px.bar(counts_all, x='ë…¸ì„ ëª…', y='ì—­ê°œìˆ˜', text='ì—­ê°œìˆ˜')
fig.update_layout(xaxis_title='ë…¸ì„ ', yaxis_title='ì—­ ê°œìˆ˜', xaxis_tickangle=-45, height=400)
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# Show table and allow selecting a row to highlight on the map
st.subheader("ì—­ ëª©ë¡")
st.dataframe(filtered.reset_index(drop=True))

st.info("ì‚¬ìš©ë²•: station.csv íŒŒì¼ì„ ì•± í´ë”ì— ë„£ê³  Streamlit Cloudì— ë°°í¬í•˜ì„¸ìš”. requirements.txtì— folium, streamlit_folium, plotlyë¥¼ ì¶”ê°€í•˜ë©´ ì§€ë„/ê·¸ë˜í”„ê°€ í–¥ìƒë©ë‹ˆë‹¤.")

# End of file
